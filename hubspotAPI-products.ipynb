{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "from sqlalchemy import create_engine, types\n",
    "from sqlalchemy.pool import NullPool\n",
    "from hubspot.crm.products import ApiException as ProductsApiException\n",
    "from hubspot.auth.oauth import ApiException\n",
    "from validate_email import validate_email\n",
    "import hubspot\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DATABASE_CONNECTION_URI = os.environ[\"NEW_DB_URL\"]\n",
    "ACCESS_TOKEN = os.environ[\"ACCESS_TOKEN\"]\n",
    "client_id = os.environ[\"CLIENT_ID\"]\n",
    "client_secret = os.environ[\"CLIENT_SECRET\"]\n",
    "\n",
    "# create a connection to the database\n",
    "engine = create_engine(DATABASE_CONNECTION_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubspotAPI:\n",
    "    def __init__(self):\n",
    "        # API KEY\n",
    "        self.access_token = ACCESS_TOKEN\n",
    "        self.client = hubspot.Client.create(access_token = self.access_token)\n",
    "        self.max_results = 1000000\n",
    "\n",
    "    def raw_export_products(self, properties_dict):\n",
    "        # Assistant Variables\n",
    "        results = []\n",
    "        after = 0\n",
    "\n",
    "        while str(after).isnumeric() and len(results) < self.max_results:\n",
    "            try:\n",
    "                api_response = self.client.crm.products.basic_api.get_page(\n",
    "                    limit=100,\n",
    "                    after=after,\n",
    "                    properties=list(properties_dict.keys()),\n",
    "                    associations=[],\n",
    "                    archived=False,\n",
    "                )\n",
    "                api_response = api_response.to_dict()\n",
    "                results.extend(api_response['results'])\n",
    "                print(\"Hubspot Products Export has gathered \" + str(len(results)) + \" Products\")\n",
    "                try:\n",
    "                    after = api_response['paging']['next']['after']\n",
    "                except:\n",
    "                    after = api_response['paging']\n",
    "            except ProductsApiException as e:\n",
    "                print(\"Exception when calling basic_api->get_page: %s\\n\" % e)\n",
    "        property_results = []\n",
    "        for result in results:\n",
    "            property_results.append(result[\"properties\"])\n",
    "        df = pd.DataFrame(property_results)\n",
    "        df.to_csv(\"raw_hubspot_products.csv\", encoding=\"latin-1\", index=False, errors='ignore')\n",
    "\n",
    "    def handle_raw_hubspot(self, csv_file, general_values, properties_dict, values_dict, date_columns, dtype={}):\n",
    "        # Csv into Dataframe\n",
    "        df = pd.read_csv(csv_file + \".csv\", encoding=\"latin-1\")\n",
    "        # Rename Columns\n",
    "        df.rename(columns=properties_dict, inplace=True)\n",
    "        # Date Standarization\n",
    "        date_columns = [char.lower() for char in date_columns]\n",
    "        date_columns = [\"_\".join(char.split(\" \")) for char in date_columns]\n",
    "        for date_column in date_columns:\n",
    "            df[date_column] = pd.to_datetime(df[df[date_column].notna()][date_column], errors='ignore')\n",
    "            df[date_column] = df[date_column].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        # Adjust Datatypes\n",
    "        for col in list(df.columns):\n",
    "            if col not in date_columns:\n",
    "                df[col] = df[col].astype(dtype[col], errors='ignore')\n",
    "        # Rename Values\n",
    "        values_dict.update(general_values)\n",
    "        df = df.map(lambda x: str(x) if pd.notnull(x) else '')\n",
    "        df.replace(values_dict, inplace=True)\n",
    "        # Export\n",
    "        df.to_csv(csv_file[4:] + \".csv\", encoding=\"latin-1\", index=False, errors='ignore')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqlAPI:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conn = create_engine(DATABASE_CONNECTION_URI)\n",
    "\n",
    "    def str_type_into_sqltype(self, datatype_dict):\n",
    "        for i in datatype_dict:\n",
    "            if datatype_dict[i] == \"string\":\n",
    "                datatype_dict[i] = types.TEXT()\n",
    "            elif datatype_dict[i] == \"int64\":\n",
    "                datatype_dict[i] = types.NUMERIC()\n",
    "            elif datatype_dict[i] == \"float64\":\n",
    "                datatype_dict[i] = types.FLOAT()\n",
    "            elif datatype_dict[i] == \"datetime64\":\n",
    "                datatype_dict[i] = types.TIMESTAMP()\n",
    "            elif datatype_dict[i] == \"bool\":\n",
    "                datatype_dict[i] = types.BOOLEAN()\n",
    "        return datatype_dict\n",
    "\n",
    "    def insert_df(self, dataframe, table, dtype, index=False, if_exists=\"replace\"):\n",
    "        dataframe.to_sql(\n",
    "            name=table,\n",
    "            con=self.conn,\n",
    "            index=index,\n",
    "            if_exists=if_exists,\n",
    "            method='multi',\n",
    "            dtype=dtype,\n",
    "            chunksize=10000\n",
    "        )\n",
    "\n",
    "    def update_table(self, table, dtype):\n",
    "\n",
    "        print(\"Update Started \" + table)\n",
    "        csv_name = table + \".csv\"\n",
    "        df = pd.read_csv(csv_name, encoding='latin-1')\n",
    "        columns = [column.lower() for column in df.columns]\n",
    "        columns = [\"_\".join(column.split(\" \")) for column in columns]\n",
    "        df.columns = columns\n",
    "        dtype = self.str_type_into_sqltype(dtype)\n",
    "        self.insert_df(df, table, dtype)\n",
    "        print(\"Update Finished \" + table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_into_simple_dict(complex_dict, simple_value):\n",
    "    headers = list(complex_dict.keys())\n",
    "    simple_values_list = []\n",
    "    for k in complex_dict:\n",
    "        simple_values_list.append(complex_dict[k][simple_value])\n",
    "    return dict(zip(headers, simple_values_list))\n",
    "\n",
    "\n",
    "def list_of_datetimes(complex_dict):\n",
    "    lst = []\n",
    "    simple_dict = dict_into_simple_dict(complex_dict, \"datatype\")\n",
    "    for item in simple_dict:\n",
    "        if simple_dict[item] == \"datetime64\":\n",
    "            lst.append(item)\n",
    "    return lst\n",
    "\n",
    "def update_database():\n",
    "    # DB Schema Handling\n",
    "    api_schema = json.load(open(\"api_schema_copy.json\"))[\"API\"]\n",
    "    hubspot_schema = api_schema[\"Hubspot\"]\n",
    "   \n",
    "    # Hubspot Schema\n",
    "    h_products_properties = dict_into_simple_dict(hubspot_schema[\"Products\"][\"Properties\"], \"header_name\")\n",
    "    h_products_values = hubspot_schema[\"Products\"][\"Values\"]\n",
    "    h_products_datecolumns = list_of_datetimes(hubspot_schema[\"Products\"][\"Properties\"])\n",
    "    h_products_datecolumns = [h_products_properties[i] for i in h_products_datecolumns]\n",
    "    h_products_datatypes = dict(zip(h_products_properties.values(),\n",
    "                                    dict_into_simple_dict(hubspot_schema[\"Products\"][\"Properties\"],\n",
    "                                                          \"datatype\").values()))\n",
    "   \n",
    "    h_generalvalues = hubspot_schema[\"General Values\"]\n",
    "    \n",
    "    # Class Variables Declaration\n",
    "    s = SqlAPI()\n",
    "    h = HubspotAPI()\n",
    "\n",
    "    # Hubspot Export\n",
    "    h.raw_export_products(h_products_properties)\n",
    " \n",
    "    # Data Handle\n",
    "    h.handle_raw_hubspot(\"raw_hubspot_products\", h_generalvalues, h_products_properties, h_products_values,\n",
    "                         h_products_datecolumns, h_products_datatypes)\n",
    "  \n",
    "    # Tablas a actualizar en la DB\n",
    "    tables = [\n",
    "        \"hubspot_products\"\n",
    "    ]\n",
    "\n",
    "    tables_datatypes = [\n",
    "        h_products_datatypes\n",
    "    ]\n",
    "    for index, table in enumerate(tables):\n",
    "        s.update_table(table, tables_datatypes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hubspot Products Export has gathered 72 Products\n",
      "Update Started hubspot_products\n",
      "Update Finished hubspot_products\n"
     ]
    }
   ],
   "source": [
    "update_database()\n",
    "\n",
    "os.remove(\"raw_hubspot_products\" + \".csv\")\n",
    "os.remove(\"hubspot_products\" + \".csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
