{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "from sqlalchemy import create_engine, types\n",
    "from sqlalchemy.pool import NullPool\n",
    "\n",
    "from hubspot.crm.quotes import ApiException as QuotesApiException\n",
    "\n",
    "\n",
    "from hubspot.crm.contacts import SimplePublicObjectInput, ApiException\n",
    "from hubspot.auth.oauth import ApiException\n",
    "from validate_email import validate_email\n",
    "import hubspot\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DATABASE_CONNECTION_URI = os.environ[\"NEW_DB_URL\"]\n",
    "ACCESS_TOKEN = os.environ[\"ACCESS_TOKEN\"]\n",
    "client_id = os.environ[\"CLIENT_ID\"]\n",
    "client_secret = os.environ[\"CLIENT_SECRET\"]\n",
    "\n",
    "# create a connection to the database\n",
    "engine = create_engine(DATABASE_CONNECTION_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubspotAPI:\n",
    "    def __init__(self):\n",
    "        # API KEY\n",
    "        self.access_token = ACCESS_TOKEN\n",
    "        self.client = hubspot.Client.create(access_token = self.access_token)\n",
    "        self.max_results = 1000000\n",
    "\n",
    "    def raw_export_quotes(self, properties_dict):\n",
    "        # Assistant Variables\n",
    "        results = []\n",
    "        after = 0\n",
    "\n",
    "        while str(after).isnumeric() and len(results) < self.max_results:\n",
    "            try:\n",
    "                api_response = self.client.crm.quotes.basic_api.get_page(\n",
    "                    limit=100,\n",
    "                    after=after,\n",
    "                    properties=list(properties_dict.keys()),\n",
    "                    associations=[\"deals\", \"line_items\"],\n",
    "                    archived=False,\n",
    "                )\n",
    "                api_response = api_response.to_dict()\n",
    "                results.extend(api_response['results'])\n",
    "                print(\"Hubspot Quotes Export has gathered \" + str(len(results)) + \" Quotes\")\n",
    "                try:\n",
    "                    after = api_response['paging']['next']['after']\n",
    "                except:\n",
    "                    after = api_response['paging']\n",
    "            except QuotesApiException as e:\n",
    "                print(\"Exception when calling basic_api->get_page: %s\\n\" % e)\n",
    "        property_results = []\n",
    "        for result in results:\n",
    "            property_results.append(result[\"properties\"])\n",
    "        df = pd.DataFrame(property_results)\n",
    "        df.to_csv(\"raw_hubspot_quotes.csv\", encoding=\"latin-1\", index=False, errors='ignore')\n",
    "        assoc_results = []\n",
    "        itterator = results.copy()\n",
    "        for result in itterator:\n",
    "            try:\n",
    "                lists_to_append = result[\"associations\"][\"deals\"][\"results\"]\n",
    "                to_append = []\n",
    "                for i in lists_to_append:\n",
    "                    dict_to_append = {}\n",
    "                    dict_to_append[\"quote_id\"] = result[\"id\"]\n",
    "                    dict_to_append[\"deal_id\"] = i[\"id\"]\n",
    "                    to_append.append(dict_to_append)\n",
    "                assoc_results.append(to_append)\n",
    "            except:\n",
    "                assoc_results.append([{\"quote_id\": result[\"id\"], \"deal_id\": None}])\n",
    "        contacts_id = []\n",
    "        deal_id = []\n",
    "        for index, item in enumerate(assoc_results):\n",
    "            i = 0\n",
    "            for a, b in item:\n",
    "                contacts_id.append(item[i][a])\n",
    "                deal_id.append(item[i][b])\n",
    "                i += 1\n",
    "        df = pd.DataFrame({\"quote_id\": contacts_id, \"deal_id\": deal_id})\n",
    "        df.to_csv(\"hubspot_quotes_to_deals.csv\", encoding=\"latin-1\", index=False, errors='ignore')\n",
    "        assoc_results = []\n",
    "        for result in itterator:\n",
    "            try:\n",
    "                lists_to_append = result[\"associations\"][\"line items\"][\"results\"]\n",
    "                to_append = []\n",
    "                for i in lists_to_append:\n",
    "                    dict_to_append = {}\n",
    "                    dict_to_append[\"quote_id\"] = result[\"id\"]\n",
    "                    dict_to_append[\"line_item_id\"] = i[\"id\"]\n",
    "                    to_append.append(dict_to_append)\n",
    "                assoc_results.append(to_append)\n",
    "            except Exception as e:\n",
    "                assoc_results.append([{\"quote_id\": result[\"id\"], \"line_item_id\": None}])\n",
    "        contacts_id = []\n",
    "        companies_id = []\n",
    "        for index, item in enumerate(assoc_results):\n",
    "            i = 0\n",
    "            for a, b in item:\n",
    "                contacts_id.append(item[i][a])\n",
    "                companies_id.append(item[i][b])\n",
    "                i += 1\n",
    "        df = pd.DataFrame({\"quote_id\": contacts_id, \"line_item_id\": companies_id})\n",
    "        df.to_csv(\"hubspot_quotes_to_line_items.csv\", encoding=\"latin-1\", index=False, errors='ignore')\n",
    "\n",
    "\n",
    "    def handle_raw_hubspot(self, csv_file, general_values, properties_dict, values_dict, date_columns, dtype={}):\n",
    "        # Csv into Dataframe\n",
    "        df = pd.read_csv(csv_file + \".csv\", encoding=\"latin-1\")\n",
    "        # Rename Columns\n",
    "        df.rename(columns=properties_dict, inplace=True)\n",
    "        # Date Standarization\n",
    "        date_columns = [char.lower() for char in date_columns]\n",
    "        date_columns = [\"_\".join(char.split(\" \")) for char in date_columns]\n",
    "        for date_column in date_columns:\n",
    "            df[date_column] = pd.to_datetime(df[df[date_column].notna()][date_column], errors='ignore')\n",
    "            df[date_column] = df[date_column].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        # Adjust Datatypes\n",
    "        for col in list(df.columns):\n",
    "            if col not in date_columns:\n",
    "                df[col] = df[col].astype(dtype[col], errors='ignore')\n",
    "        # Rename Values\n",
    "        values_dict.update(general_values)\n",
    "        df = df.map(lambda x: str(x) if pd.notnull(x) else '')\n",
    "        df.replace(values_dict, inplace=True)\n",
    "        # Export\n",
    "        df.to_csv(csv_file[4:] + \".csv\", encoding=\"latin-1\", index=False, errors='ignore')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqlAPI:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conn = create_engine(DATABASE_CONNECTION_URI)\n",
    "\n",
    "    def str_type_into_sqltype(self, datatype_dict):\n",
    "        for i in datatype_dict:\n",
    "            if datatype_dict[i] == \"string\":\n",
    "                datatype_dict[i] = types.TEXT()\n",
    "            elif datatype_dict[i] == \"int64\":\n",
    "                datatype_dict[i] = types.NUMERIC()\n",
    "            elif datatype_dict[i] == \"float64\":\n",
    "                datatype_dict[i] = types.FLOAT()\n",
    "            elif datatype_dict[i] == \"datetime64\":\n",
    "                datatype_dict[i] = types.TIMESTAMP()\n",
    "            elif datatype_dict[i] == \"bool\":\n",
    "                datatype_dict[i] = types.BOOLEAN()\n",
    "        return datatype_dict\n",
    "\n",
    "    def insert_df(self, dataframe, table, dtype, index=False, if_exists=\"replace\"):\n",
    "        dataframe.to_sql(\n",
    "            name=table,\n",
    "            con=self.conn,\n",
    "            index=index,\n",
    "            if_exists=if_exists,\n",
    "            method='multi',\n",
    "            dtype=dtype,\n",
    "            chunksize=10000\n",
    "        )\n",
    "\n",
    "    def update_table(self, table, dtype):\n",
    "\n",
    "        print(\"Update Started \" + table)\n",
    "        csv_name = table + \".csv\"\n",
    "        df = pd.read_csv(csv_name, encoding='latin-1')\n",
    "        columns = [column.lower() for column in df.columns]\n",
    "        columns = [\"_\".join(column.split(\" \")) for column in columns]\n",
    "        df.columns = columns\n",
    "        dtype = self.str_type_into_sqltype(dtype)\n",
    "        self.insert_df(df, table, dtype)\n",
    "        print(\"Update Finished \" + table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_into_simple_dict(complex_dict, simple_value):\n",
    "    headers = list(complex_dict.keys())\n",
    "    simple_values_list = []\n",
    "    for k in complex_dict:\n",
    "        simple_values_list.append(complex_dict[k][simple_value])\n",
    "    return dict(zip(headers, simple_values_list))\n",
    "\n",
    "\n",
    "def list_of_datetimes(complex_dict):\n",
    "    lst = []\n",
    "    simple_dict = dict_into_simple_dict(complex_dict, \"datatype\")\n",
    "    for item in simple_dict:\n",
    "        if simple_dict[item] == \"datetime64\":\n",
    "            lst.append(item)\n",
    "    return lst\n",
    "\n",
    "def update_database():\n",
    "    # DB Schema Handling\n",
    "    api_schema = json.load(open(\"api_schema_copy.json\"))[\"API\"]\n",
    "    hubspot_schema = api_schema[\"Hubspot\"]\n",
    "   \n",
    "    # Hubspot Schema\n",
    "    h_quotes_properties = dict_into_simple_dict(hubspot_schema[\"Quotes\"][\"Properties\"], \"header_name\")\n",
    "    h_quotes_values = hubspot_schema[\"Quotes\"][\"Values\"]\n",
    "    h_quotes_datecolumns = list_of_datetimes(hubspot_schema[\"Quotes\"][\"Properties\"])\n",
    "    h_quotes_datecolumns = [h_quotes_properties[i] for i in h_quotes_datecolumns]\n",
    "    h_quotes_datatypes = dict(zip(h_quotes_properties.values(),\n",
    "                                    dict_into_simple_dict(hubspot_schema[\"Quotes\"][\"Properties\"],\n",
    "                                                          \"datatype\").values()))\n",
    "   \n",
    "    h_generalvalues = hubspot_schema[\"General Values\"]\n",
    "    \n",
    "    # Class Variables Declaration\n",
    "    s = SqlAPI()\n",
    "    h = HubspotAPI()\n",
    "\n",
    "    # Hubspot Export\n",
    "    h.raw_export_quotes(h_quotes_properties)\n",
    " \n",
    "    # Data Handle\n",
    "    h.handle_raw_hubspot(\"raw_hubspot_quotes\", h_generalvalues, h_quotes_properties, h_quotes_values,\n",
    "                         h_quotes_datecolumns, h_quotes_datatypes)\n",
    "  \n",
    "    # Tablas a actualizar en la DB\n",
    "    tables = [\n",
    "        \"hubspot_quotes\",\n",
    "        \"hubspot_quotes_to_deals\",\n",
    "        \"hubspot_quotes_to_line_items\",\n",
    "        #\"hubspot_contacts_to_companies\",\n",
    "        #\"hubspot_contacts_to_deals\",\n",
    "        #\"hubspot_companies_to_deals\",\n",
    "    ]\n",
    "\n",
    "    tables_datatypes = [\n",
    "        h_quotes_datatypes,\n",
    "        h_quotes_datatypes,\n",
    "        h_quotes_datatypes,\n",
    "    ]\n",
    "    for index, table in enumerate(tables):\n",
    "        s.update_table(table, tables_datatypes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hubspot Quotes Export has gathered 49 Quotes\n",
      "Update Started hubspot_quotes\n",
      "Update Finished hubspot_quotes\n",
      "Update Started hubspot_quotes_to_deals\n",
      "Update Finished hubspot_quotes_to_deals\n",
      "Update Started hubspot_quotes_to_line_items\n",
      "Update Finished hubspot_quotes_to_line_items\n"
     ]
    }
   ],
   "source": [
    "update_database()\n",
    "\n",
    "os.remove(\"raw_hubspot_quotes\" + \".csv\")\n",
    "os.remove(\"hubspot_quotes\" + \".csv\")\n",
    "os.remove(\"hubspot_quotes_to_deals\" + \".csv\")\n",
    "os.remove(\"hubspot_quotes_to_line_items\" + \".csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
